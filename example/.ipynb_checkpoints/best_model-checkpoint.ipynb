{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np, re\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "def parse_data(file_name):\n",
    "    features = list()\n",
    "    labels = list()\n",
    "    with open(file_name, 'rt') as f:\n",
    "        f.readline()\n",
    "        for l in f:\n",
    "            if bool(re.search(\"^[0-9]\", l)):\n",
    "                g = re.search(\"^(([0-9]{1,2},?)+)\\s(.*)$\", l)\n",
    "                labels.append([int(i) for i in g.group(1).split(\",\")])\n",
    "                features.append(eval(\"{\" + re.sub(\"\\s\", \",\", g.group(3)) + \"}\"))\n",
    "            else:\n",
    "                l = l.strip()\n",
    "                labels.append([])\n",
    "                features.append(eval(\"{\" + re.sub(\"\\s\", \",\", l) + \"}\"))\n",
    "    features = pd.DataFrame.from_dict(features).fillna(0).iloc[:,:].values\n",
    "    mlb = MultiLabelBinarizer()\n",
    "    y = mlb.fit_transform(labels)\n",
    "    return features, y\n",
    "\n",
    "X, y = parse_data(\"data4.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aziza/.local/lib/python3.6/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.linear_model.logistic module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.linear_model. Anything that cannot be imported from sklearn.linear_model is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Streaming models\n",
    "# Same data and metaheuristics as before, but this time fitting the data in small batches,\n",
    "# without letting the algorithms have access to all their historical data\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from contextualbandits.online import AdaptiveGreedy\n",
    "from copy import deepcopy\n",
    "\n",
    "\n",
    "nchoices = y.shape[1]\n",
    "base_algorithm = SGDClassifier(random_state=123, loss='log', max_iter=2000)\n",
    "beta_prior = ((3, 7), 2) # until there are at least 2 observations of each class, will use prior Beta(3, 7)\n",
    "\n",
    "## The base algorithm is embedded in different metaheuristics\n",
    "adaptive_greedy_perc = AdaptiveGreedy(deepcopy(base_algorithm), nchoices = nchoices, beta_prior=beta_prior,\n",
    "                                      decay_type='percentile', decay=0.9997, batch_train=True)\n",
    "\n",
    "models = [adaptive_greedy_perc]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These lists will keep track of the rewards obtained by each policy\n",
    "\n",
    "rewards_agr2 = []\n",
    "\n",
    "lst_rewards = [rewards_agr2]\n",
    "\n",
    "\n",
    "# batch size - algorithms will be refit after N rounds\n",
    "batch_size = 10\n",
    "\n",
    "# initial seed - all policies start with the same small random selection of actions/rewards\n",
    "first_batch = X[:batch_size, :]\n",
    "action_chosen = np.random.randint(nchoices, size=batch_size)\n",
    "rewards_received = y[np.arange(batch_size), action_chosen]\n",
    "\n",
    "# fitting models for the first time\n",
    "for model in models:\n",
    "    np.random.seed(123)\n",
    "    model.fit(X=first_batch, a=action_chosen, r=rewards_received)\n",
    "    \n",
    "# these lists will keep track of which actions does each policy choose\n",
    "\n",
    "lst_a_agr2 = action_chosen.copy()\n",
    "lst_actions = [lst_a_agr2]\n",
    "\n",
    "# rounds are simulated from the full dataset\n",
    "def simulate_rounds_stoch(model, rewards, actions_hist, X_batch, y_batch, rnd_seed):\n",
    "    np.random.seed(rnd_seed)\n",
    "    \n",
    "    ## choosing actions for this batch\n",
    "    actions_this_batch = model.predict(X_batch).astype('uint8')\n",
    "    \n",
    "    # keeping track of the sum of rewards received\n",
    "    rewards.append(y_batch[np.arange(y_batch.shape[0]), actions_this_batch].sum())\n",
    "    \n",
    "    # adding this batch to the history of selected actions\n",
    "    new_actions_hist = np.append(actions_hist, actions_this_batch)\n",
    "    \n",
    "    # rewards obtained now\n",
    "    rewards_batch = y_batch[np.arange(y_batch.shape[0]), actions_this_batch]\n",
    "    \n",
    "    # now refitting the algorithms after observing these new rewards\n",
    "    np.random.seed(rnd_seed)\n",
    "    model.partial_fit(X_batch, actions_this_batch, rewards_batch)\n",
    "    \n",
    "    return new_actions_hist\n",
    "\n",
    "# now running all the simulation\n",
    "for i in range(int(np.floor(X.shape[0] / batch_size))):\n",
    "    batch_st = (i + 1) * batch_size\n",
    "    batch_end = (i + 2) * batch_size\n",
    "    batch_end = np.min([batch_end, X.shape[0]])\n",
    "    \n",
    "    X_batch = X[batch_st:batch_end, :]\n",
    "    y_batch = y[batch_st:batch_end, :]\n",
    "    \n",
    "    for model in range(len(models)):\n",
    "        lst_actions[model] = simulate_rounds_stoch(models[model],\n",
    "                                                   lst_rewards[model],\n",
    "                                                   lst_actions[model],\n",
    "                                                   X_batch, y_batch,\n",
    "                                                   rnd_seed = batch_st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n"
     ]
    }
   ],
   "source": [
    "idx = np.random.randint(len(X))\n",
    "action = models[0].predict(X[13580, :]).astype(\"uint8\")\n",
    "print(action)\n",
    "# for i in idx:\n",
    "#   action = models[model].predict(X[idx, :]).astype(\"uint8\")\n",
    "#   print(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
